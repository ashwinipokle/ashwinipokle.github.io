---
layout: post
title:  "Visually-Grounded Library of Behaviors for Generalizing Manipulation Across Objects, Configurations and Views"
date:  2021-07-01 22:21:59 +00:00
image: /images/manip.png
categories: research
authors: "Hsiao-Yu Tung*, Jingyun Yang*, Yunchu Zhang*, Gaurav Pathak, <strong>Ashwini Pokle</strong>, Christopher G. Atkeson, and Katerina Fragkiadaki"
venue: "Conference on Robot Learning (CoRL)"
arxiv: https://arxiv.org/abs/1905.05279
code: https://github.com/YunchuZhang/Visually-Grounded-Library-of-Behaviors
---
We propose a method for manipulating diverse objects across a wide range of initial and goal configurations and camera placements. We disentangle the standard image-to-action mapping into two separate modules: (1) a behavior selector which selects the behaviors that can successfully perform the desired tasks on the object in hand, and (2) a library of behaviors each of which conditions on extrinsic and abstract object properties to predict actions to execute over time.
